{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35ec5690-5517-4918-9aa0-da54ea845c2c",
   "metadata": {},
   "source": [
    "# Feature store"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e40448-b555-413c-8b5e-0a3c3e9db10b",
   "metadata": {},
   "source": [
    "\n",
    "Дословно - «магазин» фичей - удобный интерфейс для взаимодействия data-engineer и data-science процессов\n",
    "\n",
    "Более подробно - Feature Store представляет собой хранилище данных для обучения и инференса ML-моделей и совокупность процессов по:\n",
    "- хранению и версионированию признаков\n",
    "- заведению новых признаков и их подробного описания\n",
    "- обогащению экспертизы по feature-engineering для построения ml-моделей\n",
    "- (опционально) регулярный пересчет признаков\n",
    "\n",
    "Feature store помогает бизнесу эффективнее делиться экспертизой в создании признаков для обучения моделей между командами и бизнес-доменами, а также помогает data - отделам эффективнее мониторить расчет признаков, сдвиги распределений данных и другие свойства датасетов, влияющие на финальную точность алгоритмов машинного обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538da5d4-be6e-416a-ae5b-2d6095c0b6b7",
   "metadata": {},
   "source": [
    "![title](./images/feature_store_overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9d614b-1c76-47c4-b976-89e2c10e4600",
   "metadata": {},
   "source": [
    "### Feature Store в компаниях\n",
    "\n",
    "Большинство компаний формируют архитектуру Feature Store детально под свои нужды и единого бенчмарка Feature Store не существует, но ниже приведу несколько примеров архитектур Feature store в разных крупных компаниях"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7827d8-ce89-44bd-b7ab-68a61608c70b",
   "metadata": {},
   "source": [
    "#### Spotify"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f2e725-5b1f-48b4-aa73-07416e5e860d",
   "metadata": {},
   "source": [
    "![title](./images/spotify_feature_store.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05abb0-68a9-4621-8f92-6d6e295a36dd",
   "metadata": {},
   "source": [
    "#### Twitter\n",
    "\n",
    "![title](./images/twitter_feature_store.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba583ef0-8ea3-4deb-8bf3-4fc9be275e7b",
   "metadata": {},
   "source": [
    "#### Linkedin\n",
    "\n",
    "![title](./images/linkedin_feature_store.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd8c402-7180-4467-bc28-2389315fe532",
   "metadata": {},
   "source": [
    "Как можно заметить, внутри компаний инфраструктуры Feature Store довольно сильно отличаются\n",
    "\n",
    "В первую очередь это связано с устройством и наличием специфичных in-house инструментов внутри крупных компаний, а также с уникальностью домена данных, Feature Store для обработки звуковых данных может сильно отличаться от Feature Store для хранения данных о банковских транзакциях.\n",
    "\n",
    "Стоит отметить и общие моменты, например для realtime - данных зачастую используется уже зарекомендовавший себя брокер обмена сообщениями - Kafka, но более важная деталь, характеризующая Feature Store - **глобально Feature Store - это про подход работы с данными**, который с технической точки зрения может включать в себя не только Python SDK для обращения к признакам, но и инструменты для сбора данных, хранения, расчета и методологии версионирования.\n",
    "\n",
    "Также, важно понимать, что за действительно рабочим Feature Store стоит также и работа над бизнес - процессами, связанными с хранением и созданием признаков, выделением ресурсов на аккуратное их заведение в регистр признаков и донесение информации о них другим ds - командам в компании.\n",
    "\n",
    "Без налаженных процессов построенный Feauture Store быстро устареет и перестанет использоваться, может превратиться в дополнительную обузу на онбординге для новых разработчиков и Data Scientist'ов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83fa91b-f389-46a8-824b-476ed7d86131",
   "metadata": {},
   "source": [
    "### [Feast](https://github.com/feast-dev/feast)\n",
    "\n",
    "На примере архитектуры Feature Store в компании X (быв. Twitter) можно заметить использование open-source решение для создания Feature Store - [Feast](https://feast.dev/)\n",
    "\n",
    "Feast представляет собой интерфейс Feature store в виде Python SDK и коннекторов к различным источникам данных, как стриминговых (Kafka, Kinesis), так и к батчевым (S3, Parquet, Snowflake, BigQuery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d0fd78-1317-4a0d-917c-d9e1bfe32df5",
   "metadata": {},
   "source": [
    "![title](./images/feast_overview.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bd006-b301-4446-8dec-83ad60d13ac0",
   "metadata": {},
   "source": [
    "#### Компоненты Feast\n",
    "\n",
    "##### Registry – Главная директория Feature store, содержащая все метаданные признакового поля\n",
    "\n",
    "##### Store – Делится на offline/online, online не содержит истории, только самый актуальный срез признакового описания объектов\n",
    "\n",
    "##### Serve – Интерфейс (Python SDK) для взаимодействия с данными (их выгрузки и регистрации)\n",
    "\n",
    "![title](./images/feast_architecture.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a874a-6594-44b9-a975-a4d567881ce1",
   "metadata": {},
   "source": [
    "- Create Batch Features: ELT/ETL системы для преобразования данных\n",
    "- Create Stream Features: потоковые сервисы поставки данных (Kafka/Kinesis)\n",
    "- Feast Apply: обновление инфраструктуры feature store согласно указанным конфигурационным файлам feast\n",
    "- Feast Materialize: выгрузка данных в онлайн хранилище\n",
    "- Model Training: пайплайн для получения данных перед обучением модели\n",
    "- Get Historical Features: экспорт истории по признакам для подачи данных в модели\n",
    "- Deploy Model: запуск модели (не покрывается feast'ом)\n",
    "- Prediction: получение предсказаний модели\n",
    "- Get Online Features: получение потоковых данных для обучнеия модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14229872-2064-4d9f-997d-2e2dc68c9b4e",
   "metadata": {},
   "source": [
    "Feast является наиболее популярным open-source решением для внедрения Feature Store, однако при его внедрении стоит помнить о нескольких ограничениях:\n",
    "\n",
    "#### Feast НЕ является\n",
    "\n",
    "- ELT/ETL система, Feast не поддерживает пайплайны для обработки данных, их лучше выносить в отдельные приложения\n",
    "- Оркестратор, для этого лучше выбрать Apache Airflow / Apache Nifi\n",
    "- База данных, инструмент предназначен для обработки данных из БД, а не хранения их внутри себя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c2faff-d026-433f-88e6-30084d8d75bb",
   "metadata": {},
   "source": [
    "### Feast пример использования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4087ac-2c24-469e-8b43-6f13885b1ba0",
   "metadata": {},
   "source": [
    "#### Инициализация проекта"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3165b5-38bd-4f56-b05d-1bc439eece66",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r test_project; mkdir test_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdfe33c-08e9-4e67-b38a-9a5dd604809f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install feast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4bad44-6e37-4585-b142-61382822fc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating a new Feast repository in \u001b[1m\u001b[32m/Users/alexeytarasov/temp/feature_store/test_project\u001b[0m.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!feast init test_project\n",
    "!cd test_project/feature_repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b59c59b-2d40-4eb5-bcaf-dfb4e4775f16",
   "metadata": {},
   "source": [
    "Посмотрим, что содержится в папке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78249dbe-ab52-4da1-9adf-11d1af515d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./test_project/feature_repo/__init__.py\n",
      "./test_project/feature_repo/example_repo.py\n",
      "./test_project/feature_repo/feature_store.yaml\n",
      "./test_project/feature_repo/test_workflow.py\n",
      "\n",
      "./test_project/feature_repo/__pycache__:\n",
      "__init__.cpython-39.pyc      test_workflow.cpython-39.pyc\n",
      "example_repo.cpython-39.pyc\n",
      "\n",
      "./test_project/feature_repo/data:\n",
      "driver_stats.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls ./test_project/feature_repo/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c47ab0-343d-42fa-b3f3-bf1c22e109ca",
   "metadata": {},
   "source": [
    "- example_repo.py содержит определение признаков\n",
    "- feature_store.yaml содержит настройки для инициализации нашего feature store\n",
    "- test_workflow.py пример для запуска команд по выгрузке признаков из feature store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf398ce-6b3a-47cd-835e-eb3d6bb189f2",
   "metadata": {},
   "source": [
    "#### Содержание конфигурационных файлов для создания feature store с помощью Feast\n",
    "\n",
    "`feature_store.yaml`\n",
    "\n",
    "```\n",
    "project: my_project\n",
    "# By default, the registry is a file (but can be turned into a more scalable SQL-backed registry)\n",
    "registry: data/registry.db\n",
    "# The provider primarily specifies default offline / online stores & storing the registry in a given cloud\n",
    "provider: local\n",
    "online_store:\n",
    "  type: sqlite\n",
    "  path: data/online_store.db\n",
    "entity_key_serialization_version: 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bcfbba-e2d2-4fe3-af49-da46c295df98",
   "metadata": {},
   "source": [
    "`example_repo.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d812d8e-01e9-406a-b9c5-23acc6556062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an example feature definition file\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from feast import (\n",
    "    Entity,\n",
    "    FeatureService,\n",
    "    FeatureView,\n",
    "    Field,\n",
    "    FileSource,\n",
    "    PushSource,\n",
    "    RequestSource,\n",
    ")\n",
    "from feast.on_demand_feature_view import on_demand_feature_view\n",
    "from feast.types import Float32, Float64, Int64\n",
    "\n",
    "# Define an entity for the driver. You can think of entity as a primary key used to\n",
    "# fetch features.\n",
    "driver = Entity(name=\"driver\", join_keys=[\"driver_id\"])\n",
    "\n",
    "# Read data from parquet files. Parquet is convenient for local development mode. For\n",
    "# production, you can use your favorite DWH, such as BigQuery. See Feast documentation\n",
    "# for more info.\n",
    "driver_stats_source = FileSource(\n",
    "    name=\"driver_hourly_stats_source\",\n",
    "    path=\"%PARQUET_PATH%\",\n",
    "    timestamp_field=\"event_timestamp\",\n",
    "    created_timestamp_column=\"created\",\n",
    ")\n",
    "\n",
    "# Our parquet files contain sample data that includes a driver_id column, timestamps and\n",
    "# three feature column. Here we define a Feature View that will allow us to serve this\n",
    "# data to our model online.\n",
    "driver_stats_fv = FeatureView(\n",
    "    # The unique name of this feature view. Two feature views in a single\n",
    "    # project cannot have the same name\n",
    "    name=\"driver_hourly_stats\",\n",
    "    entities=[driver],\n",
    "    ttl=timedelta(days=1),\n",
    "    # The list of features defined below act as a schema to both define features\n",
    "    # for both materialization of features into a store, and are used as references\n",
    "    # during retrieval for building a training dataset or serving features\n",
    "    schema=[\n",
    "        Field(name=\"conv_rate\", dtype=Float32),\n",
    "        Field(name=\"acc_rate\", dtype=Float32),\n",
    "        Field(name=\"avg_daily_trips\", dtype=Int64),\n",
    "    ],\n",
    "    online=True,\n",
    "    source=driver_stats_source,\n",
    "    # Tags are user defined key/value pairs that are attached to each\n",
    "    # feature view\n",
    "    tags={\"team\": \"driver_performance\"},\n",
    ")\n",
    "\n",
    "# Defines a way to push data (to be available offline, online or both) into Feast.\n",
    "driver_stats_push_source = PushSource(\n",
    "    name=\"driver_stats_push_source\",\n",
    "    batch_source=driver_stats_source,\n",
    ")\n",
    "\n",
    "# Define a request data source which encodes features / information only\n",
    "# available at request time (e.g. part of the user initiated HTTP request)\n",
    "input_request = RequestSource(\n",
    "    name=\"vals_to_add\",\n",
    "    schema=[\n",
    "        Field(name=\"val_to_add\", dtype=Int64),\n",
    "        Field(name=\"val_to_add_2\", dtype=Int64),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Define an on demand feature view which can generate new features based on\n",
    "# existing feature views and RequestSource features\n",
    "@on_demand_feature_view(\n",
    "    sources=[driver_stats_fv, input_request],\n",
    "    schema=[\n",
    "        Field(name=\"conv_rate_plus_val1\", dtype=Float64),\n",
    "        Field(name=\"conv_rate_plus_val2\", dtype=Float64),\n",
    "    ],\n",
    ")\n",
    "def transformed_conv_rate(inputs: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = pd.DataFrame()\n",
    "    df[\"conv_rate_plus_val1\"] = inputs[\"conv_rate\"] + inputs[\"val_to_add\"]\n",
    "    df[\"conv_rate_plus_val2\"] = inputs[\"conv_rate\"] + inputs[\"val_to_add_2\"]\n",
    "    return df\n",
    "\n",
    "\n",
    "# This groups features into a model version\n",
    "driver_activity_v1 = FeatureService(\n",
    "    name=\"driver_activity_v1\",\n",
    "    features=[\n",
    "        driver_stats_fv[[\"conv_rate\"]],  # Sub-selects a feature from a feature view\n",
    "        transformed_conv_rate,  # Selects all features from the feature view\n",
    "    ],\n",
    ")\n",
    "driver_activity_v2 = FeatureService(\n",
    "    name=\"driver_activity_v2\", features=[driver_stats_fv, transformed_conv_rate]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb6d60-a62a-40d3-880c-76f0fbb24d72",
   "metadata": {},
   "source": [
    "#### Запуск тестового workflow\n",
    "\n",
    "Для запуска тестового процесса выгрузки признаков можно запустить:\n",
    "\n",
    "`python test_workflow.py`\n",
    "\n",
    "Ниже указан код `test_workflow.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f7687-90b0-4f73-856e-a7e3c9bf2eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from feast import FeatureStore\n",
    "from feast.data_source import PushMode\n",
    "\n",
    "\n",
    "def run_demo():\n",
    "    store = FeatureStore(repo_path=\".\")\n",
    "    print(\"\\n--- Run feast apply ---\")\n",
    "    subprocess.run([\"feast\", \"apply\"])\n",
    "\n",
    "    print(\"\\n--- Historical features for training ---\")\n",
    "    fetch_historical_features_entity_df(store, for_batch_scoring=False)\n",
    "\n",
    "    print(\"\\n--- Historical features for batch scoring ---\")\n",
    "    fetch_historical_features_entity_df(store, for_batch_scoring=True)\n",
    "\n",
    "    print(\"\\n--- Load features into online store ---\")\n",
    "    store.materialize_incremental(end_date=datetime.now())\n",
    "\n",
    "    print(\"\\n--- Online features ---\")\n",
    "    fetch_online_features(store)\n",
    "\n",
    "    print(\"\\n--- Online features retrieved (instead) through a feature service---\")\n",
    "    fetch_online_features(store, source=\"feature_service\")\n",
    "\n",
    "    print(\n",
    "        \"\\n--- Online features retrieved (using feature service v3, which uses a feature view with a push source---\"\n",
    "    )\n",
    "    fetch_online_features(store, source=\"push\")\n",
    "\n",
    "    print(\"\\n--- Simulate a stream event ingestion of the hourly stats df ---\")\n",
    "    event_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            \"driver_id\": [1001],\n",
    "            \"event_timestamp\": [\n",
    "                datetime.now(),\n",
    "            ],\n",
    "            \"created\": [\n",
    "                datetime.now(),\n",
    "            ],\n",
    "            \"conv_rate\": [1.0],\n",
    "            \"acc_rate\": [1.0],\n",
    "            \"avg_daily_trips\": [1000],\n",
    "        }\n",
    "    )\n",
    "    print(event_df)\n",
    "    store.push(\"driver_stats_push_source\", event_df, to=PushMode.ONLINE_AND_OFFLINE)\n",
    "\n",
    "    print(\"\\n--- Online features again with updated values from a stream push---\")\n",
    "    fetch_online_features(store, source=\"push\")\n",
    "\n",
    "    print(\"\\n--- Run feast teardown ---\")\n",
    "    subprocess.run([\"feast\", \"teardown\"])\n",
    "\n",
    "\n",
    "def fetch_historical_features_entity_df(store: FeatureStore, for_batch_scoring: bool):\n",
    "    # Note: see https://docs.feast.dev/getting-started/concepts/feature-retrieval for more details on how to retrieve\n",
    "    # for all entities in the offline store instead\n",
    "    entity_df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            # entity's join key -> entity values\n",
    "            \"driver_id\": [1001, 1002, 1003],\n",
    "            # \"event_timestamp\" (reserved key) -> timestamps\n",
    "            \"event_timestamp\": [\n",
    "                datetime(2021, 4, 12, 10, 59, 42),\n",
    "                datetime(2021, 4, 12, 8, 12, 10),\n",
    "                datetime(2021, 4, 12, 16, 40, 26),\n",
    "            ],\n",
    "            # (optional) label name -> label values. Feast does not process these\n",
    "            \"label_driver_reported_satisfaction\": [1, 5, 3],\n",
    "            # values we're using for an on-demand transformation\n",
    "            \"val_to_add\": [1, 2, 3],\n",
    "            \"val_to_add_2\": [10, 20, 30],\n",
    "        }\n",
    "    )\n",
    "    # For batch scoring, we want the latest timestamps\n",
    "    if for_batch_scoring:\n",
    "        entity_df[\"event_timestamp\"] = pd.to_datetime(\"now\", utc=True)\n",
    "\n",
    "    training_df = store.get_historical_features(\n",
    "        entity_df=entity_df,\n",
    "        features=[\n",
    "            \"driver_hourly_stats:conv_rate\",\n",
    "            \"driver_hourly_stats:acc_rate\",\n",
    "            \"driver_hourly_stats:avg_daily_trips\",\n",
    "            \"transformed_conv_rate:conv_rate_plus_val1\",\n",
    "            \"transformed_conv_rate:conv_rate_plus_val2\",\n",
    "        ],\n",
    "    ).to_df()\n",
    "    print(training_df.head())\n",
    "\n",
    "\n",
    "def fetch_online_features(store, source: str = \"\"):\n",
    "    entity_rows = [\n",
    "        # {join_key: entity_value}\n",
    "        {\n",
    "            \"driver_id\": 1001,\n",
    "            \"val_to_add\": 1000,\n",
    "            \"val_to_add_2\": 2000,\n",
    "        },\n",
    "        {\n",
    "            \"driver_id\": 1002,\n",
    "            \"val_to_add\": 1001,\n",
    "            \"val_to_add_2\": 2002,\n",
    "        },\n",
    "    ]\n",
    "    if source == \"feature_service\":\n",
    "        features_to_fetch = store.get_feature_service(\"driver_activity_v1\")\n",
    "    elif source == \"push\":\n",
    "        features_to_fetch = store.get_feature_service(\"driver_activity_v3\")\n",
    "    else:\n",
    "        features_to_fetch = [\n",
    "            \"driver_hourly_stats:acc_rate\",\n",
    "            \"transformed_conv_rate:conv_rate_plus_val1\",\n",
    "            \"transformed_conv_rate:conv_rate_plus_val2\",\n",
    "        ]\n",
    "    returned_features = store.get_online_features(\n",
    "        features=features_to_fetch,\n",
    "        entity_rows=entity_rows,\n",
    "    ).to_dict()\n",
    "    for key, value in sorted(returned_features.items()):\n",
    "        print(key, \" : \", value)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8e5ade-e328-4bee-a425-c9e7576df4db",
   "metadata": {},
   "source": [
    "### Масштабирование Feast\n",
    "\n",
    "#### Registry\n",
    "Для использования Feast в production - среде доступны следующие варианты ведения registry:\n",
    "- S3\n",
    "- GCP\n",
    "- Snowflake\n",
    "- Postgres\n",
    "- MySQL\n",
    "\n",
    "Для SQL - based форматов ведения registry будет необходипо прописать подключение в `feature_store.yaml`, например - вот так:\n",
    "\n",
    "```\n",
    "project: <your project name>\n",
    "provider: <provider name>\n",
    "online_store: redis\n",
    "offline_store: file\n",
    "registry:\n",
    "    registry_type: sql\n",
    "    path: postgresql://postgres:mysecretpassword@127.0.0.1:55001/feast\n",
    "    cache_ttl_seconds: 60\n",
    "```\n",
    "\n",
    "#### Offline store\n",
    "\n",
    "Доступные варианты для offline-store компоненты:\n",
    "\n",
    "- File\n",
    "- Snowflake\n",
    "- BigQuery\n",
    "- Redshift\n",
    "- Spark*\n",
    "- Postgres*\n",
    "- Trino*\n",
    "\n",
    "\n",
    "#### Online store\n",
    "\n",
    "То же самое для online-store\n",
    "\n",
    "- Sqlite\n",
    "- Redis\n",
    "- DynamoDB\n",
    "- Snowflake\n",
    "- Postgres*\n",
    "- Hbase*\n",
    "- Cassandra*\n",
    "\n",
    "\\* - поддерживается feast - commiunity, не гарантируется стабильность работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b930d3d-e5f7-4f33-b927-f6a8fbeea1ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
